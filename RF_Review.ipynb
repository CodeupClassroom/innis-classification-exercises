{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from acquire import get_titanic_data\n",
    "# This is the version of prepare included in the florence classification exercises repo:\n",
    "from prepare import prep_titanic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    }
   ],
   "source": [
    "# acquire the data\n",
    "df = get_titanic_data()\n",
    "# prepare the data\n",
    "train, validate, test = prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex        age  sibsp  parch  \\\n",
       "583           583         0       1    male  36.000000      0      0   \n",
       "337           337         1       1  female  41.000000      0      0   \n",
       "50             50         0       3    male   7.000000      4      1   \n",
       "218           218         1       1  female  32.000000      0      0   \n",
       "31             31         1       1  female  29.916875      1      0   \n",
       "\n",
       "         fare embarked  class  embark_town  alone  Q  S  \n",
       "583   40.1250        C  First    Cherbourg      1  0  0  \n",
       "337  134.5000        C  First    Cherbourg      1  0  0  \n",
       "50    39.6875        S  Third  Southampton      0  0  1  \n",
       "218   76.2917        C  First    Cherbourg      1  0  0  \n",
       "31   146.5208        C  First    Cherbourg      0  0  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop out non-numerical columns or non-encoded version remaining in this data set\n",
    "drops = ['sex', 'class','embarked', 'embark_town', 'passenger_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train, validate, test]:\n",
    "    dataset.drop(columns=drops, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  Q  S\n",
       "583         0       1  36.000000      0      0   40.1250      1  0  0\n",
       "337         1       1  41.000000      0      0  134.5000      1  0  0\n",
       "50          0       3   7.000000      4      1   39.6875      0  0  1\n",
       "218         1       1  32.000000      0      0   76.2917      1  0  0\n",
       "31          1       1  29.916875      1      0  146.5208      0  0  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns='survived'), train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived    0.617706\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish our baseline.  The rate at which the assumption of the majority class matches the real values.  If a model does not perform better than this, it would not be wise to deploy.\n",
    "baseline = (y_train.value_counts().idxmax() == y_train).mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming everyone perished is roughly 62% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Random Forest Model\n",
    "clf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=1349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=1349)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the thing\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the thing\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9276\n",
      "    The True Positive Rate is 0.868, The False Positive Rate is 0.0358,\n",
      "    The True Negative Rate is 0.964, and the False Negative Rate is 0.132\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922118</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.929809</td>\n",
       "      <td>0.927999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.964169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.916295</td>\n",
       "      <td>0.927565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.922157</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.922118    0.937500  0.927565    0.929809      0.927999\n",
       "recall       0.964169    0.868421  0.927565    0.916295      0.927565\n",
       "f1-score     0.942675    0.901639  0.927565    0.922157      0.926987\n",
       "support    307.000000  190.000000  0.927565  497.000000    497.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score = clf.score(X_train, y_train)\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is survival, with a binary 0 representing a passenger that did not surivive the titanic wreck\n",
    "# and 1 representing a survivor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Random Forest Model\n",
    "clf1 = RandomForestClassifier(min_samples_leaf=3, max_depth=3, random_state=1349)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=1349)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.7525\n",
      "    The True Positive Rate is 0.537, The False Positive Rate is 0.114,\n",
      "    The True Negative Rate is 0.886, and the False Negative Rate is 0.463\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922118</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.929809</td>\n",
       "      <td>0.927999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.964169</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.916295</td>\n",
       "      <td>0.927565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942675</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>0.922157</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.927565</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.922118    0.937500  0.927565    0.929809      0.927999\n",
       "recall       0.964169    0.868421  0.927565    0.916295      0.927565\n",
       "f1-score     0.942675    0.901639  0.927565    0.922157      0.926987\n",
       "support    307.000000  190.000000  0.927565  497.000000    497.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = clf1.predict(X_train)\n",
    "clf_score = clf1.score(X_train, y_train)\n",
    "conf = confusion_matrix(y_train, y_pred1)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = validate.drop(columns='survived'), validate.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1: min samples 1, max depth 10: ON VALIDATE SET\n",
      "\n",
      "    The accuracy for our model is 0.7617\n",
      "    The True Positive Rate is 0.646, The False Positive Rate is 0.167,\n",
      "    The True Negative Rate is 0.833, and the False Negative Rate is 0.354\n",
      "    \n",
      "-------------------------------------------\n",
      " Model #2: min samples 3, max_depth 3 : ON VALIDATE SET\n",
      "\n",
      "\n",
      "    The accuracy for our model is 0.743\n",
      "    The True Positive Rate is 0.5, The False Positive Rate is 0.106,\n",
      "    The True Negative Rate is 0.894, and the False Negative Rate is 0.5\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('Model #1: min samples 1, max depth 10: ON VALIDATE SET')\n",
    "clf_score = clf.score(X_val, y_val)\n",
    "y_pred_val = clf.predict(X_val)\n",
    "conf = confusion_matrix(y_val, y_pred_val)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "print('-------------------------------------------\\n Model #2: min samples 3, max_depth 3 : ON VALIDATE SET\\n')\n",
    "clf_score = clf1.score(X_val, y_val)\n",
    "y_pred_val1 = clf1.predict(X_val)\n",
    "conf = confusion_matrix(y_val, y_pred_val1)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {clf_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[296,  11],\n",
       "       [ 25, 165]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy:\n",
    "# accuracy = (true positives + true negatives) / (true positives + true negatives + false positives + false negatives)\n",
    "\n",
    "# True Positive Rate: Sensitivity\n",
    "# RECALL for the positive class --> out of those that actually survived, how many did we predict would survive?\n",
    "# TPR = true positives / (true positives + false negatives)\n",
    "#  If we wanted to calculate PRECISION, it would be true positives / (true positives + false postives)\n",
    "# Recall being true positives over the sum of the row, precision being the true positive over the sum of the column\n",
    "# i.e, out of the values we predicted survived, how many were actual survivors?\n",
    "\n",
    "# False Positive Rate: \n",
    "# FPR = false positives / (false positive + true negatives)\n",
    "\n",
    "# True Negative Rate: Specificity\n",
    "# Recall for the negative class --> out of those that perished, how many did we predict would not make it?\n",
    "# TNR = true negatives / (true negatives + false positives)\n",
    "\n",
    "# False negative rate:\n",
    "# FNR = false negatives / (false negatives + true positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70104785, 0.29895215],\n",
       "       [0.06711869, 0.93288131],\n",
       "       [0.9758    , 0.0242    ],\n",
       "       [0.10064358, 0.89935642],\n",
       "       [0.0443181 , 0.9556819 ],\n",
       "       [0.68404055, 0.31595945],\n",
       "       [0.47006918, 0.52993082],\n",
       "       [0.67405366, 0.32594634],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82134381, 0.17865619],\n",
       "       [0.89806093, 0.10193907],\n",
       "       [0.13108025, 0.86891975],\n",
       "       [0.59453012, 0.40546988],\n",
       "       [0.60759589, 0.39240411],\n",
       "       [0.38816308, 0.61183692],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.18171429, 0.81828571],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.78048702, 0.21951298],\n",
       "       [0.13383776, 0.86616224],\n",
       "       [0.82246706, 0.17753294],\n",
       "       [0.2079232 , 0.7920768 ],\n",
       "       [0.19833333, 0.80166667],\n",
       "       [0.38900423, 0.61099577],\n",
       "       [0.93237155, 0.06762845],\n",
       "       [0.12313969, 0.87686031],\n",
       "       [0.77758204, 0.22241796],\n",
       "       [0.58227628, 0.41772372],\n",
       "       [0.67053517, 0.32946483],\n",
       "       [0.85851765, 0.14148235],\n",
       "       [0.75484745, 0.24515255],\n",
       "       [0.92370488, 0.07629512],\n",
       "       [0.04768984, 0.95231016],\n",
       "       [0.22601563, 0.77398437],\n",
       "       [0.18027778, 0.81972222],\n",
       "       [0.74415807, 0.25584193],\n",
       "       [0.0596152 , 0.9403848 ],\n",
       "       [0.79486773, 0.20513227],\n",
       "       [0.73784029, 0.26215971],\n",
       "       [0.86005014, 0.13994986],\n",
       "       [0.81075661, 0.18924339],\n",
       "       [0.90496667, 0.09503333],\n",
       "       [0.37851492, 0.62148508],\n",
       "       [0.5731157 , 0.4268843 ],\n",
       "       [0.93241277, 0.06758723],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.90088236, 0.09911764],\n",
       "       [0.5731029 , 0.4268971 ],\n",
       "       [0.7666286 , 0.2333714 ],\n",
       "       [0.91547289, 0.08452711],\n",
       "       [0.84069255, 0.15930745],\n",
       "       [0.16117767, 0.83882233],\n",
       "       [0.05594747, 0.94405253],\n",
       "       [0.59250786, 0.40749214],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.83666942, 0.16333058],\n",
       "       [0.17482381, 0.82517619],\n",
       "       [0.34008241, 0.65991759],\n",
       "       [0.92063425, 0.07936575],\n",
       "       [0.70071813, 0.29928187],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.98718893, 0.01281107],\n",
       "       [0.63788704, 0.36211296],\n",
       "       [0.73349848, 0.26650152],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.08295586, 0.91704414],\n",
       "       [0.97817787, 0.02182213],\n",
       "       [0.17611851, 0.82388149],\n",
       "       [0.07955   , 0.92045   ],\n",
       "       [0.94      , 0.06      ],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.14183408, 0.85816592],\n",
       "       [0.23233633, 0.76766367],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.82846273, 0.17153727],\n",
       "       [0.88996544, 0.11003456],\n",
       "       [0.88497769, 0.11502231],\n",
       "       [0.85356935, 0.14643065],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.55264654, 0.44735346],\n",
       "       [0.01562189, 0.98437811],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.59250786, 0.40749214],\n",
       "       [0.90834427, 0.09165573],\n",
       "       [0.69828571, 0.30171429],\n",
       "       [0.55339281, 0.44660719],\n",
       "       [0.08962624, 0.91037376],\n",
       "       [0.05516855, 0.94483145],\n",
       "       [0.88497769, 0.11502231],\n",
       "       [0.9507045 , 0.0492955 ],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.23229147, 0.76770853],\n",
       "       [0.05853477, 0.94146523],\n",
       "       [0.62384949, 0.37615051],\n",
       "       [0.92561734, 0.07438266],\n",
       "       [0.18691687, 0.81308313],\n",
       "       [0.81784127, 0.18215873],\n",
       "       [0.82209022, 0.17790978],\n",
       "       [0.57422022, 0.42577978],\n",
       "       [0.9076779 , 0.0923221 ],\n",
       "       [0.73552381, 0.26447619],\n",
       "       [0.24772643, 0.75227357],\n",
       "       [0.92075841, 0.07924159],\n",
       "       [0.62229437, 0.37770563],\n",
       "       [0.09444455, 0.90555545],\n",
       "       [0.87077778, 0.12922222],\n",
       "       [0.08586666, 0.91413334],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.11232749, 0.88767251],\n",
       "       [0.12612082, 0.87387918],\n",
       "       [0.78427497, 0.21572503],\n",
       "       [0.87136462, 0.12863538],\n",
       "       [0.93579263, 0.06420737],\n",
       "       [0.17899516, 0.82100484],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85130215, 0.14869785],\n",
       "       [0.08194455, 0.91805545],\n",
       "       [0.17710255, 0.82289745],\n",
       "       [0.83302659, 0.16697341],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.45745595, 0.54254405],\n",
       "       [0.90769791, 0.09230209],\n",
       "       [0.44776311, 0.55223689],\n",
       "       [0.48610091, 0.51389909],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.66000158, 0.33999842],\n",
       "       [0.48255263, 0.51744737],\n",
       "       [0.9358    , 0.0642    ],\n",
       "       [0.06407323, 0.93592677],\n",
       "       [0.89978306, 0.10021694],\n",
       "       [0.9808    , 0.0192    ],\n",
       "       [0.3192716 , 0.6807284 ],\n",
       "       [0.66505911, 0.33494089],\n",
       "       [0.88202362, 0.11797638],\n",
       "       [0.89716117, 0.10283883],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.52714657, 0.47285343],\n",
       "       [0.66445971, 0.33554029],\n",
       "       [0.34893111, 0.65106889],\n",
       "       [0.5968727 , 0.4031273 ],\n",
       "       [0.72762096, 0.27237904],\n",
       "       [0.88293763, 0.11706237],\n",
       "       [0.7845821 , 0.2154179 ],\n",
       "       [0.16068023, 0.83931977],\n",
       "       [0.217675  , 0.782325  ],\n",
       "       [0.51473801, 0.48526199],\n",
       "       [0.09414863, 0.90585137],\n",
       "       [0.4328094 , 0.5671906 ],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.37540969, 0.62459031],\n",
       "       [0.1397112 , 0.8602888 ],\n",
       "       [0.94167187, 0.05832813],\n",
       "       [0.75353488, 0.24646512],\n",
       "       [0.25075372, 0.74924628],\n",
       "       [0.95738845, 0.04261155],\n",
       "       [0.94167187, 0.05832813],\n",
       "       [0.38900423, 0.61099577],\n",
       "       [0.96150371, 0.03849629],\n",
       "       [0.88084127, 0.11915873],\n",
       "       [0.36633433, 0.63366567],\n",
       "       [0.72333117, 0.27666883],\n",
       "       [0.51597755, 0.48402245],\n",
       "       [0.93083705, 0.06916295],\n",
       "       [0.98016291, 0.01983709],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.81130215, 0.18869785],\n",
       "       [0.75629929, 0.24370071],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.76486901, 0.23513099],\n",
       "       [0.0690814 , 0.9309186 ],\n",
       "       [0.13113768, 0.86886232],\n",
       "       [0.8510878 , 0.1489122 ],\n",
       "       [0.81907075, 0.18092925],\n",
       "       [0.87914557, 0.12085443],\n",
       "       [0.75741964, 0.24258036],\n",
       "       [0.9935246 , 0.0064754 ],\n",
       "       [0.97498246, 0.02501754],\n",
       "       [0.61889703, 0.38110297],\n",
       "       [0.92533426, 0.07466574],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.91715647, 0.08284353],\n",
       "       [0.4417864 , 0.5582136 ],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.7787234 , 0.2212766 ],\n",
       "       [0.81601526, 0.18398474],\n",
       "       [0.10035952, 0.89964048],\n",
       "       [0.89692308, 0.10307692],\n",
       "       [0.63237491, 0.36762509],\n",
       "       [0.75730758, 0.24269242],\n",
       "       [0.07090959, 0.92909041],\n",
       "       [0.94120771, 0.05879229],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.02482778, 0.97517222],\n",
       "       [0.01316111, 0.98683889],\n",
       "       [0.73405217, 0.26594783],\n",
       "       [0.27488624, 0.72511376],\n",
       "       [0.90601504, 0.09398496],\n",
       "       [0.91662937, 0.08337063],\n",
       "       [1.        , 0.        ],\n",
       "       [0.2833677 , 0.7166323 ],\n",
       "       [0.05338055, 0.94661945],\n",
       "       [0.92555538, 0.07444462],\n",
       "       [0.79905518, 0.20094482],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.80328602, 0.19671398],\n",
       "       [0.61784644, 0.38215356],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.38895184, 0.61104816],\n",
       "       [0.87870632, 0.12129368],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.70705721, 0.29294279],\n",
       "       [0.56743186, 0.43256814],\n",
       "       [0.23939524, 0.76060476],\n",
       "       [0.11685076, 0.88314924],\n",
       "       [0.91169879, 0.08830121],\n",
       "       [0.88293763, 0.11706237],\n",
       "       [0.29632334, 0.70367666],\n",
       "       [0.98259679, 0.01740321],\n",
       "       [0.54540655, 0.45459345],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.82072969, 0.17927031],\n",
       "       [0.30041715, 0.69958285],\n",
       "       [0.99857143, 0.00142857],\n",
       "       [0.9507045 , 0.0492955 ],\n",
       "       [0.54725408, 0.45274592],\n",
       "       [0.31731815, 0.68268185],\n",
       "       [0.90438994, 0.09561006],\n",
       "       [0.26002441, 0.73997559],\n",
       "       [0.62857944, 0.37142056],\n",
       "       [0.88003061, 0.11996939],\n",
       "       [0.92047293, 0.07952707],\n",
       "       [0.84716342, 0.15283658],\n",
       "       [0.91662937, 0.08337063],\n",
       "       [0.26687433, 0.73312567],\n",
       "       [0.265     , 0.735     ],\n",
       "       [0.98718893, 0.01281107],\n",
       "       [0.88382842, 0.11617158],\n",
       "       [0.97746667, 0.02253333],\n",
       "       [0.94120771, 0.05879229],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.11741028, 0.88258972],\n",
       "       [0.17667717, 0.82332283],\n",
       "       [0.02062189, 0.97937811],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.06407323, 0.93592677],\n",
       "       [0.96220092, 0.03779908],\n",
       "       [0.2254543 , 0.7745457 ],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.80188818, 0.19811182],\n",
       "       [0.5180364 , 0.4819636 ],\n",
       "       [0.92378443, 0.07621557],\n",
       "       [0.3325494 , 0.6674506 ],\n",
       "       [0.70717819, 0.29282181],\n",
       "       [0.33181818, 0.66818182],\n",
       "       [0.94959875, 0.05040125],\n",
       "       [0.07197777, 0.92802223],\n",
       "       [0.10939258, 0.89060742],\n",
       "       [0.40738353, 0.59261647],\n",
       "       [0.53187622, 0.46812378],\n",
       "       [0.87577115, 0.12422885],\n",
       "       [0.22395145, 0.77604855],\n",
       "       [0.63011331, 0.36988669],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.87082968, 0.12917032],\n",
       "       [0.96416667, 0.03583333],\n",
       "       [0.33212895, 0.66787105],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.85190868, 0.14809132],\n",
       "       [0.86302395, 0.13697605],\n",
       "       [0.70692399, 0.29307601],\n",
       "       [0.96470405, 0.03529595],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95651534, 0.04348466],\n",
       "       [0.84119107, 0.15880893],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.92925282, 0.07074718],\n",
       "       [0.92925282, 0.07074718],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.69318588, 0.30681412],\n",
       "       [0.51145258, 0.48854742],\n",
       "       [0.8457094 , 0.1542906 ],\n",
       "       [0.85846304, 0.14153696],\n",
       "       [0.16907323, 0.83092677],\n",
       "       [0.53187622, 0.46812378],\n",
       "       [0.70665152, 0.29334848],\n",
       "       [0.77695759, 0.22304241],\n",
       "       [0.86943559, 0.13056441],\n",
       "       [0.80548335, 0.19451665],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.95470405, 0.04529595],\n",
       "       [0.61184565, 0.38815435],\n",
       "       [0.05517808, 0.94482192],\n",
       "       [0.72478512, 0.27521488],\n",
       "       [0.90438994, 0.09561006],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.96558151, 0.03441849],\n",
       "       [0.16176498, 0.83823502],\n",
       "       [0.86005014, 0.13994986],\n",
       "       [0.96750371, 0.03249629],\n",
       "       [0.08356666, 0.91643334],\n",
       "       [0.92378443, 0.07621557],\n",
       "       [0.86806093, 0.13193907],\n",
       "       [0.22714141, 0.77285859],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.80585382, 0.19414618],\n",
       "       [0.65456825, 0.34543175],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.85656411, 0.14343589],\n",
       "       [0.929862  , 0.070138  ],\n",
       "       [0.31873585, 0.68126415],\n",
       "       [0.9708    , 0.0292    ],\n",
       "       [0.90494398, 0.09505602],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.0847697 , 0.9152303 ],\n",
       "       [0.14621739, 0.85378261],\n",
       "       [0.99711012, 0.00288988],\n",
       "       [0.95514332, 0.04485668],\n",
       "       [0.88545459, 0.11454541],\n",
       "       [0.42539182, 0.57460818],\n",
       "       [0.71172434, 0.28827566],\n",
       "       [0.83474629, 0.16525371],\n",
       "       [0.46478376, 0.53521624],\n",
       "       [0.30275502, 0.69724498],\n",
       "       [0.3467012 , 0.6532988 ],\n",
       "       [0.13561625, 0.86438375],\n",
       "       [0.10276596, 0.89723404],\n",
       "       [0.95249611, 0.04750389],\n",
       "       [0.5230589 , 0.4769411 ],\n",
       "       [0.16155   , 0.83845   ],\n",
       "       [0.07372013, 0.92627987],\n",
       "       [0.13108025, 0.86891975],\n",
       "       [0.43168132, 0.56831868],\n",
       "       [0.96246667, 0.03753333],\n",
       "       [0.09195758, 0.90804242],\n",
       "       [0.84069255, 0.15930745],\n",
       "       [0.32905365, 0.67094635],\n",
       "       [0.71822338, 0.28177662],\n",
       "       [0.04768984, 0.95231016],\n",
       "       [0.11117098, 0.88882902],\n",
       "       [0.23920481, 0.76079519],\n",
       "       [0.88005276, 0.11994724],\n",
       "       [0.2565246 , 0.7434754 ],\n",
       "       [0.85846304, 0.14153696],\n",
       "       [0.66274864, 0.33725136],\n",
       "       [0.5747074 , 0.4252926 ],\n",
       "       [0.90306093, 0.09693907],\n",
       "       [0.23662333, 0.76337667],\n",
       "       [0.88084127, 0.11915873],\n",
       "       [0.5815418 , 0.4184582 ],\n",
       "       [0.31224799, 0.68775201],\n",
       "       [0.08194455, 0.91805545],\n",
       "       [0.10326172, 0.89673828],\n",
       "       [0.10294179, 0.89705821],\n",
       "       [0.9358    , 0.0642    ],\n",
       "       [0.90494398, 0.09505602],\n",
       "       [0.20618806, 0.79381194],\n",
       "       [0.93849144, 0.06150856],\n",
       "       [0.25165152, 0.74834848],\n",
       "       [0.0468181 , 0.9531819 ],\n",
       "       [0.75256818, 0.24743182],\n",
       "       [0.89992115, 0.10007885],\n",
       "       [0.47637323, 0.52362677],\n",
       "       [0.21274688, 0.78725312],\n",
       "       [0.96484454, 0.03515546],\n",
       "       [0.9858    , 0.0142    ],\n",
       "       [0.48602974, 0.51397026],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.77441417, 0.22558583],\n",
       "       [0.82246706, 0.17753294],\n",
       "       [0.71000691, 0.28999309],\n",
       "       [0.26737577, 0.73262423],\n",
       "       [0.91169879, 0.08830121],\n",
       "       [0.09639013, 0.90360987],\n",
       "       [0.68659382, 0.31340618],\n",
       "       [0.1591506 , 0.8408494 ],\n",
       "       [0.36902413, 0.63097587],\n",
       "       [0.29395835, 0.70604165],\n",
       "       [0.42539182, 0.57460818],\n",
       "       [0.26203571, 0.73796429],\n",
       "       [0.9296812 , 0.0703188 ],\n",
       "       [0.62201558, 0.37798442],\n",
       "       [0.27640638, 0.72359362],\n",
       "       [0.98862949, 0.01137051],\n",
       "       [0.46502082, 0.53497918],\n",
       "       [0.68147475, 0.31852525],\n",
       "       [0.81032248, 0.18967752],\n",
       "       [0.9888734 , 0.0111266 ],\n",
       "       [0.05356666, 0.94643334],\n",
       "       [0.62759293, 0.37240707],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.25094094, 0.74905906],\n",
       "       [0.84334639, 0.15665361],\n",
       "       [0.42506754, 0.57493246],\n",
       "       [0.98926345, 0.01073655],\n",
       "       [0.88474629, 0.11525371],\n",
       "       [0.83101963, 0.16898037],\n",
       "       [0.89475307, 0.10524693],\n",
       "       [0.10833333, 0.89166667],\n",
       "       [0.75946979, 0.24053021],\n",
       "       [0.55003686, 0.44996314],\n",
       "       [0.65977752, 0.34022248],\n",
       "       [0.50713632, 0.49286368],\n",
       "       [0.63537803, 0.36462197],\n",
       "       [0.83466349, 0.16533651],\n",
       "       [0.90953212, 0.09046788],\n",
       "       [0.76420849, 0.23579151],\n",
       "       [0.90917862, 0.09082138],\n",
       "       [0.97905543, 0.02094457],\n",
       "       [0.7367753 , 0.2632247 ],\n",
       "       [0.93692308, 0.06307692],\n",
       "       [0.13024689, 0.86975311],\n",
       "       [0.20310472, 0.79689528],\n",
       "       [0.0705619 , 0.9294381 ],\n",
       "       [0.92561734, 0.07438266],\n",
       "       [0.09457896, 0.90542104],\n",
       "       [0.67447927, 0.32552073],\n",
       "       [0.23229147, 0.76770853],\n",
       "       [0.94142077, 0.05857923],\n",
       "       [0.9378264 , 0.0621736 ],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [0.49127534, 0.50872466],\n",
       "       [0.12232381, 0.87767619],\n",
       "       [0.86297519, 0.13702481],\n",
       "       [0.19024059, 0.80975941],\n",
       "       [0.8919934 , 0.1080066 ],\n",
       "       [0.5742246 , 0.4257754 ],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.78831401, 0.21168599],\n",
       "       [0.88253128, 0.11746872],\n",
       "       [0.78384745, 0.21615255],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.45560234, 0.54439766],\n",
       "       [0.71409229, 0.28590771],\n",
       "       [0.92075841, 0.07924159],\n",
       "       [0.22912333, 0.77087667],\n",
       "       [0.55339281, 0.44660719],\n",
       "       [0.94876677, 0.05123323],\n",
       "       [0.95182945, 0.04817055],\n",
       "       [0.91968655, 0.08031345],\n",
       "       [0.53861036, 0.46138964],\n",
       "       [0.93498531, 0.06501469],\n",
       "       [0.31185822, 0.68814178],\n",
       "       [0.97746667, 0.02253333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10356599, 0.89643401],\n",
       "       [0.96917521, 0.03082479],\n",
       "       [0.31468859, 0.68531141],\n",
       "       [0.28948212, 0.71051788],\n",
       "       [0.96220092, 0.03779908],\n",
       "       [0.71229476, 0.28770524],\n",
       "       [0.11311869, 0.88688131],\n",
       "       [0.21601563, 0.78398437],\n",
       "       [0.95      , 0.05      ],\n",
       "       [0.57744174, 0.42255826],\n",
       "       [0.9686014 , 0.0313986 ],\n",
       "       [0.89053325, 0.10946675],\n",
       "       [0.97356277, 0.02643723],\n",
       "       [0.93367877, 0.06632123],\n",
       "       [0.58198549, 0.41801451],\n",
       "       [0.77105411, 0.22894589],\n",
       "       [0.91126639, 0.08873361],\n",
       "       [0.08084921, 0.91915079],\n",
       "       [0.51702297, 0.48297703],\n",
       "       [0.84949543, 0.15050457],\n",
       "       [0.07295586, 0.92704414],\n",
       "       [0.84039943, 0.15960057],\n",
       "       [0.10195758, 0.89804242],\n",
       "       [0.79404976, 0.20595024],\n",
       "       [0.96558151, 0.03441849],\n",
       "       [0.8638961 , 0.1361039 ],\n",
       "       [0.57688515, 0.42311485],\n",
       "       [0.98862949, 0.01137051],\n",
       "       [0.16356123, 0.83643877],\n",
       "       [0.8958    , 0.1042    ],\n",
       "       [0.66062426, 0.33937574],\n",
       "       [0.85130215, 0.14869785],\n",
       "       [0.16380159, 0.83619841],\n",
       "       [0.56909673, 0.43090327],\n",
       "       [0.26481833, 0.73518167],\n",
       "       [0.17558847, 0.82441153],\n",
       "       [0.9814894 , 0.0185106 ],\n",
       "       [0.05628919, 0.94371081],\n",
       "       [0.07777622, 0.92222378],\n",
       "       [0.05321911, 0.94678089],\n",
       "       [0.93794664, 0.06205336],\n",
       "       [0.1078181 , 0.8921819 ],\n",
       "       [0.12569643, 0.87430357],\n",
       "       [0.75090234, 0.24909766],\n",
       "       [0.93849144, 0.06150856],\n",
       "       [0.63237491, 0.36762509],\n",
       "       [0.98215607, 0.01784393],\n",
       "       [0.95514332, 0.04485668],\n",
       "       [0.42831772, 0.57168228]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preds = clf.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True,  True, False, False,  True,  True,  True, False,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True, False,\n",
       "       False, False,  True,  True, False,  True,  True,  True, False,\n",
       "       False, False,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False, False, False,  True,  True, False,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "       False,  True, False,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False, False,  True, False,  True, False,  True,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preds < .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
